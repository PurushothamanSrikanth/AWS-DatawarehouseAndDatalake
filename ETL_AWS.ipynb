{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6f1ed70-f0d0-41ff-8bf1-a4019a6e417a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\PURUSH~1\\AppData\\Local\\Temp/ipykernel_10132/2878442484.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconf\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSparkConf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "#Importing all necessary libraries\n",
    "\n",
    "import pandas, numpy, os\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b642a6d2-e393-48f2-b54a-a83a5e68a5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pyspark --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aee00af-cf7f-44c7-98f5-3ae84adc48d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a Spark Session\n",
    "\n",
    "conf = SparkConf()\\\n",
    "    .setAppName(\"Purush_ETL\")\\\n",
    "    .setMaster(\"local[2]\")\n",
    "\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .config(conf = conf)\\\n",
    "    .config(\"spark.executor.memory\", \"2g\") \\\n",
    "    .config(\"spark.executor.instances\", \"2\")\\\n",
    "    .config(\"spark.executor.cores\", \"5\")\\\n",
    "    .config(\"spark.driver.memory\", \"2g\")\\\n",
    "    .config(\"spark.dynamicAllocation.enabled\", \"true\")\\\n",
    "    .config(\"spark.dynamicAllocation.minExecutors\",\"1\")\\\n",
    "    .config(\"spark.dynamicAllocation.maxExecutors\",\"3\")\\\n",
    "    .enableHiveSupport()\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18df0cda-94a1-459a-8c24-1a7773e62088",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathforDWH = \"/user/hive/warehouse/test\"\n",
    "pathforDL = \"s3a://dwanddl/user/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8043bba3-1712-4d4c-a5f5-d0056a257e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Data Warehouse\n",
    "dwh = spark.read.parquet(pathforDWH)\n",
    "\n",
    "dwh.printSchema() #to check the Schema of the dataframe\n",
    "#dwh.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36378a57-4d2e-4c14-bf2f-549bac6dd6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Data Lake\n",
    "dl = spark.read.parquet(pathforDL)\n",
    "\n",
    "dl.printSchema() #to check the Schema of the dataframe\n",
    "#dl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d193ceb4-ce67-491b-9961-a8c0c2b40f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join\n",
    "\n",
    "consolidated_df = dwh.union(dl) #picks onty distinct records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46661e8b-4f6e-4704-b085-ee07b20a3397",
   "metadata": {},
   "outputs": [],
   "source": [
    "consolidated_df.repartion('Month').write.mode(\"overwrite\").format(\"parquet\").path(pathforDL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a259a4-1ede-4681-adce-14f158cc9c58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e7cd5b-347c-4dd7-893a-5fd16c285d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Query\n",
    "df = spark.read.parquet(pathforDL)\n",
    "df.createOrReplaceTempView(\"dbtable\")\n",
    "df.spark.sql(\"SELECT Month, COUNT(), COUNT() FROM dbtable WHERE isStudent = \"False\" GROUP BY Month\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4797de32-3b77-47da-8e33-c387c21928c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Query\n",
    "\n",
    "SELECT \n",
    "    Month,\n",
    "    COUNT(CASE WHEN minsalary = 1 THEN 1 ELSE NULL END) AS lowsalarycount,\n",
    "    COUNT(CASE WHEN maxsalary = 1 THEN 1 ELSE NULL END) AS highsalarycount\n",
    "FROM (\n",
    "SELECT\n",
    "    Month,\n",
    "    ROW_NUMBER() OVER (PARTITION BY Month ORDER BY Salary DESC) AS maxsalary,\n",
    "    ROW_NUMBER() OVER (PARTITION BY Month ORDER BY Salary ASC) AS minsalary,\n",
    "    isStudent = 'False'\n",
    ")\n",
    "GROUP BY Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0679aa-08cc-4952-81ec-8fbe29eacd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
